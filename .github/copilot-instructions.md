# Instru√ß√µes para Agentes de IA - Clipagem Chatbot

## Vis√£o Geral do Projeto

**Clipagem** √© um sistema de automa√ß√£o de clipping do **Di√°rio de Santa Maria**. O projeto automatiza:
1. Download di√°rio do PDF do jornal (via Selenium)
2. An√°lise de conte√∫do com IA (Google Gemini)
3. Exibi√ß√£o em interface web (Streamlit)

**URL Alvo**: https://diariosm.com.br/assinante/newflip  
**Credenciais**: publicacaopmsm@gmail.com / AgysIOldtw  
**Hor√°rio de Execu√ß√£o**: 06:15 BRT (09:00 UTC) de segunda a s√°bado

## Status Atual do Projeto (04/02/2026)

### ‚úÖ Componentes Funcionais
- **src/daily_scraper.py** (521 linhas): Selenium scraper com 14+ seletores robustos
- **src/analyzer.py** (230 linhas): Extra√ß√£o PDF + an√°lise Gemini 2.0 Flash
- **app.py** (349 linhas): Interface Streamlit com tema light for√ßado
- **.github/workflows/daily_run.yml**: GitHub Actions com cron schedule
- **data/**: Armazena PDF e JSON de clipping

### ‚ö†Ô∏è Problema Atual - EM ANDAMENTO
**Filtro "Public. Legal" n√£o est√° sendo aplicado**

O scraper est√° baixando PDF de publica√ß√µes legais (VALVI Companhia) em vez das edi√ß√µes jornal√≠sticas.

**Solu√ß√£o em desenvolvimento:**
- Ap√≥s login e navega√ß√£o para `/newflip`, selecionar "Exceto" no dropdown "Public. Legal"
- Elemento identificado: `<input role="combobox" id="input-v-98" ...>`
- Fun√ß√£o `set_publication_filter()` precisa ser implementada/ajustada
- Edi√ß√£o alvo confirmada: **Edi√ß√£o N¬∫ 7328 - Data: 04/02/2026**

### üîß √öltimas A√ß√µes Realizadas
1. Scraper executado com sucesso - login OK, download OK
2. PDF baixado incorretamente (VALVI em vez de Di√°rio SM)
3. Identificado filtro necess√°rio atrav√©s de inspe√ß√£o manual
4. Tentativas de implementa√ß√£o do filtro iniciadas (combobox n√£o encontrado)

## Arquitetura e Componentes

### Estrutura Real
- `src/daily_scraper.py`: Selenium + Chrome headless para login e download de PDF
- `src/analyzer.py`: PyMuPDF para extra√ß√£o + Gemini para an√°lise de conte√∫do
- `app.py`: Streamlit interface com visualiza√ß√£o de cards
- `data/`: PDF atual e JSON com an√°lise do dia
- `.streamlit/config.toml`: Configura√ß√£o de tema light
- `.github/workflows/daily_run.yml`: Automa√ß√£o via GitHub Actions

### Padr√µes de Design Implementados
- **Seletores com Fallback**: 14+ XPath para username, 10+ para password, 11+ para bot√£o
- **Chrome Binary Detection**: Detecta Chrome em 5 locais diferentes (multi-plataforma)
- **Limpeza Autom√°tica**: Remove PDFs antigos antes de baixar novo
- **Screenshot em Erro**: Salva em `/tmp/login_error.png` para debug
- **Logging Estruturado**: Prefixos [ENV], [LOGIN], [PDF], [DOWNLOAD], [GEMINI]

## Conven√ß√µes de C√≥digo

### Stack Tecnol√≥gico
- **Python 3.12.1**: Linguagem principal
- **Selenium 4.40.0**: Automa√ß√£o web com Chrome 144.0.7559.132
- **Google Gemini 2.0 Flash**: An√°lise de conte√∫do (via `google-generativeai` - deprecated)
- **Streamlit 1.53.1**: Interface web
- **PyMuPDF (fitz) 1.24.9**: Extra√ß√£o de texto de PDF
- **python-dotenv 1.0.0**: Gerenciamento de vari√°veis de ambiente

### Nomea√ß√£o e Estrutura
- Prefixos de log: `[ENV]`, `[CHROME]`, `[LOGIN]`, `[PDF]`, `[DOWNLOAD]`, `[GEMINI]`
- Fun√ß√µes em snake_case com docstrings descritivas
- Arquivos de dados: `diario_sm_atual.pdf`, `clipagem_hoje.json`
- Vari√°veis de ambiente: `DIARIO_USER`, `DIARIO_PASS`, `GEMINI_API_KEY`

### Patterns de Implementa√ß√£o
- **Seletores Robustos**: Lista de fallbacks com try/except para elementos din√¢micos
- **WebDriverWait**: Timeout padr√£o de 20s para elementos, 120s para download
- **Chrome Options**: `--headless`, `--no-sandbox`, `--disable-dev-shm-usage`
- **Download Dir**: Configurado via `prefs` do Chrome para `data/`
- **Tratamento de Erros**: Screenshot + mensagem estruturada antes de raise

## Workflows de Desenvolvimento

### Execu√ß√£o dos Scripts
```bash
# Download do PDF
cd /workspaces/clipagem
python src/daily_scraper.py

# An√°lise com Gemini (requer GEMINI_API_KEY em .env)
python src/analyzer.py

# Interface web (porta 8501)
streamlit run app.py --server.port 8501
```

### Estrutura de Dados

**clipagem_hoje.json:**
```json
{
  "data_clipping": "04 de Fevereiro de 2026",
  "noticias": [
    {
      "pagina": 1,
      "titulo": "T√≠tulo da not√≠cia",
      "resumo_120_chars": "Resumo em at√© 120 caracteres",
      "relevancia": "alta|media|baixa"
    }
  ]
}
```

### Diagn√≥stico e Debug
- **Chrome**: Bin√°rio em `/usr/bin/google-chrome`
- **Screenshot de erro**: `/tmp/login_error.png`
- **Logs estruturados**: Prefixos identificam etapa do processo
- **PDF baixado**: `/workspaces/clipagem/data/diario_sm_atual.pdf`

### Problemas Conhecidos
1. **API Gemini**: Cota free tier pode esgotar (429 error)
2. **Filtro "Public. Legal"**: N√£o aplicado, baixa PDF errado
3. **Seletores din√¢micos**: IDs mudam (input-v-98, input-v-44, etc)

## Pr√≥ximos Passos (Onde Paramos)

### üéØ Tarefa Atual: Implementar Filtro "Public. Legal"

**Problema:** O scraper baixa PDF de publica√ß√µes legais (VALVI) em vez das edi√ß√µes jornal√≠sticas.

**Solu√ß√£o Necess√°ria:**
1. Ap√≥s login, navegar para `/newflip`
2. Localizar dropdown "Public. Legal" 
3. Selecionar op√ß√£o "Exceto"
4. Aguardar atualiza√ß√£o da lista
5. Baixar PDF da edi√ß√£o jornal√≠stica

**Elemento Identificado:**
```html
<input size="1" role="combobox" type="text" 
       aria-labelledby="input-v-98-label" 
       id="input-v-98" 
       aria-describedby="input-v-98-messages" 
       aria-expanded="false" 
       aria-controls="menu-v-96" 
       value="">
```

**Status:** Fun√ß√£o `set_publication_filter()` criada mas combobox n√£o localizado nos testes.

**Edi√ß√£o Alvo Confirmada:**
- JORNAL
- Edi√ß√£o N¬∫ 7328
- Data Edi√ß√£o: 04/02/2026

### üîç Pr√≥ximas A√ß√µes Sugeridas
1. Adicionar screenshot da p√°gina `/newflip` para debug visual
2. Tentar seletores alternativos para o dropdown (aria-label, texto "Public. Legal")
3. Verificar se filtro aparece ap√≥s scroll ou aguardar carregamento
4. Implementar clique no dropdown + sele√ß√£o da op√ß√£o "Exceto"
5. Validar que PDF baixado √© da edi√ß√£o jornal√≠stica (n√£o VALVI)

---

## Integra√ß√£o com Fontes de M√≠dia

### Considera√ß√µes Principais
- Suportar m√∫ltiplas fontes (not√≠cias, redes sociais, blogs, etc)
- Respeitar rate limits e pol√≠ticas de termos de servi√ßo
- Implementar retry logic com backoff exponencial
- Cache de conte√∫do quando aplic√°vel

## Depend√™ncias Cr√≠ticas

- [A documentar conforme tecnologias forem definidas]

## Refer√™ncias para Padr√µes

- Revisar commits iniciais para decis√µes arquiteturais
- Documentar novas decis√µes de arquitetura em ADRs (Architecture Decision Records)

---

**Nota**: Este arquivo ser√° expandido conforme o projeto evolui. Agentes devem atualizar esta documenta√ß√£o quando implementarem padr√µes ou conven√ß√µes n√£o documentadas aqui.
